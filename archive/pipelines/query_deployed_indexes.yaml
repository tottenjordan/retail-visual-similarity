name: Query deployed indexes
inputs:
- {name: project, type: String}
- {name: location, type: String}
- {name: staging_bucket, type: String}
- {name: num_neighbors, type: Integer}
- {name: index_endpoint_resource_uri, type: String}
- {name: deployed_brute_force_index_name, type: String}
- {name: deployed_ann_index_name, type: String}
- {name: test_imgs_gcs_dir, type: String}
- {name: num_test_samples, type: Integer}
- {name: vertex_model_gcs_dir, type: String}
implementation:
  container:
    image: python:3.9
    command:
    - sh
    - -c
    - |2

      if ! [ -x "$(command -v pip)" ]; then
          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip
      fi

      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-aiplatform==1.16.1' 'google-cloud-storage' 'tensorflow==2.8' 'tensorflow-hub==0.12.0' 'tensorflow-estimator==2.8.0' 'keras==2.8' 'kfp==1.8.13' && "$0" "$@"
    - sh
    - -ec
    - |
      program_path=$(mktemp -d)
      printf "%s" "$0" > "$program_path/ephemeral_component.py"
      python3 -m kfp.v2.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"
    - "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing\
      \ import *\n\ndef query_deployed_indexes(\n    project: str,\n    location:\
      \ str,\n    staging_bucket: str,\n    num_neighbors: int,\n    index_endpoint_resource_uri:\
      \ str,\n    deployed_brute_force_index_name: str,\n    deployed_ann_index_name:\
      \ str,\n    test_imgs_gcs_dir: str,\n    num_test_samples: int,\n    vertex_model_gcs_dir:\
      \ str,):\n\n  import os\n  import numpy\n  import tensorflow as tf\n  import\
      \ tensorflow_hub as hub\n  from google.cloud import aiplatform\n  from datetime\
      \ import datetime\n\n  aiplatform.init(project=project, location=location, staging_bucket=staging_bucket)\n\
      \n  os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n\n  IMG_HEIGHT = 224\n\
      \  IMG_WIDTH = 224\n  IMG_CHANNELS = 3\n\n  ##############################################################################\n\
      \  # Helper Functions\n  ##############################################################################\n\
      \n  def read_and_decode(filename, reshape_dims=[IMG_HEIGHT, IMG_WIDTH]):\n \
      \   # Read the file\n    img = tf.io.read_file(filename)\n\n    # Convert the\
      \ compressed string to a 3D uint8 tensor.\n    img = tf.image.decode_jpeg(img,\
      \ channels=IMG_CHANNELS)\n\n    # Use `convert_image_dtype` to convert to floats\
      \ in the [0,1] range.\n    # This makes the img 1 x 224 x 224 x 3 tensor with\
      \ the data type of float32\n    img = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis,\
      \ ...]\n\n    # Resize the image to the desired size.\n    return tf.image.resize(img,\
      \ reshape_dims)\n\n  def create_query_embeddings(embedder, img_path):\n    dataset_filenames\
      \ = []\n    dataset_embeddings = []\n    list_dir = tf.io.gfile.listdir(img_path)\n\
      \n    for file in list_dir[:num_test_samples]:\n      img_tensor = read_and_decode(img_path\
      \ + \"/\" + file, [IMG_WIDTH, IMG_HEIGHT])\n      embeddings = embedder(img_tensor)\n\
      \      dataset_filenames.append(img_path + \"/\" + file)\n      dataset_embeddings.extend(embeddings)\n\
      \n    dataset_embeddings = tf.convert_to_tensor(dataset_embeddings)\n    return\
      \ dataset_filenames, dataset_embeddings\n\n  ##############################################################################\n\
      \  # Init IndexEndpoint, Load Model, Create Query embeddings\n  ##############################################################################\n\
      \n  index_endpoint = aiplatform.MatchingEngineIndexEndpoint(index_endpoint_resource_uri)\n\
      \n  loaded_model = tf.keras.models.load_model(vertex_model_gcs_dir)\n  print(\"\
      model summary:\", loaded_model.summary())\n\n  query_filenames, query_embeddings\
      \ = create_query_embeddings(\n      lambda x: loaded_model.predict(x),\n   \
      \   test_imgs_gcs_dir\n  )\n  print(\"query_embeddings shape:\", query_embeddings.shape)\n\
      \  print(\"query_filenames:\", query_filenames)\n\n  vector_list = []\n  for\
      \ q_vector in query_embeddings:\n    vector_list.append(q_vector.numpy())\n\n\
      \  ann_response = index_endpoint.match(\n      deployed_index_id=deployed_ann_index_name,\
      \ \n      queries=vector_list, \n      num_neighbors=num_neighbors\n  )\n  print(\"\
      ann_response:\", ann_response)\n\n  brute_force_response = index_endpoint.match(\n\
      \      deployed_index_id=deployed_brute_force_index_name, \n      queries=vector_list,\
      \ \n      num_neighbors=num_neighbors\n  )\n\n  print(\"brute_force_response:\"\
      , brute_force_response)\n\n"
    args:
    - --executor_input
    - {executorInput: null}
    - --function_to_execute
    - query_deployed_indexes
